{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성분석 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs # 인코딩 변환 시켜주는 method\n",
    "def read_data(filename):\n",
    "    with codecs.open(filename, encoding='utf-8', mode='r') as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data\n",
    "\n",
    "train_data = read_data('/home/dockeruser/data/nsmc/ratings_train.txt')\n",
    "test_data = read_data('/home/dockeruser/data/nsmc/ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = zip(*train_data)[1]\n",
    "y = zip(*train_data)[2]\n",
    "y = np.array(y, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=10000, test_size=10000)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'\\uc544 \\ub354\\ube59.. \\uc9c4\\uc9dc \\uc9dc\\uc99d\\ub098\\ub124\\uc694 \\ubaa9\\uc18c\\ub9ac',)\n"
     ]
    }
   ],
   "source": [
    "print(X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((아 더빙.. 진짜 짜증나네요 목소리,\n",
      "  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나,\n",
      "  너무재밓었다그래서보는것을추천한다,\n",
      "  교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정,\n",
      "  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다,\n",
      "  막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.,\n",
      "  원작의 긴장감을 제대로 살려내지못했다.,\n",
      "  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네,\n",
      "  액션이 없는데도 재미 있는 몇안되는 영화,\n",
      "  왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?),\n",
      " array([0, 1, 0, 0, 1, 0, 0, 0, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "from konlpy.utils import pprint # 한글 출력시 문제 해결하는 method\n",
    "pprint((X[0:10], y[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CountVectorize 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "clf_1 = Pipeline([\n",
    "            ('vect', CountVectorizer()), \n",
    "            ('clf', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[당당해,\n",
      " 죠스,\n",
      " chthonic,\n",
      " 죽어가는,\n",
      " 초석은,\n",
      " 앞으론,\n",
      " 너무아름다웠던,\n",
      " 도입부,\n",
      " 23년전에,\n",
      " 이야기끌고가는게]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(clf_1.named_steps[\"vect\"].vocabulary_)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0, 0, 1, 1, 0, 1, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "pprint(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([1, 1, 1, 1, 0, 1, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "pprint(clf_1.predict(X_test)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 4]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test[:10], clf_1.predict(X_test)[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0, 0, 0, 1, 1, 1, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "pprint(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0, 0, 0, 1, 1, 1, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "pprint(clf_1.predict(X_train)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train[:10], clf_1.predict(X_train)[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[국내 개봉하기도 전에 봤었는데.. 당시 기준에선 몇몇 볼만한 칼질씬은 있었다,\n",
      " 이처럼 조잡한 충동에 최고의 상을 부여함으로써 칸느가 자신들의 수준조차 밑돌았던 이유는 편견의 힘. 카메라의 시선은 알량하고 오만한데 이란 민중에 대한 희롱을 넘어 인간에 대한 모욕. 이런 역겨운 토사물에 꼬인 파리떼의 성찬은 당연한 결과,\n",
      " 이야!! 재밋다!! 하하하!! . . .,\n",
      " 다시 보니 수작이란걸 알게 되었습니다. 이런 영화를 평가절하했던 몇년전 어린 저에게 반성을 조금 나이먹고 보니 오히려 맨오브스틸보다 더 잘만든영화였단걸 깨닫게 되었네요 ㅜㅜ 아 차라리 이 시리즈의 후속편을 만들지,\n",
      " 리뷰가 너무 웃겨서 방금 다운받으려다 말았..ㅋㅋ,\n",
      " 8점은 되야된다고 생각해서 10점줌 ㅋㅋㅋ 배우들도 아는 배우들이 보이니까 더 재밋엇네요 ㅋㅋ,\n",
      " 정말 재미없고도 어슬프게 재미있었다.,\n",
      " 마지막까지 답답한 영화. 아빠가 목졸려 죽을 것 같은 상황에 경찰이 왔으면 잽싸게 달려나가 문을 열어줘야지ㅋㅋㅋ 답답하고 어설픈 안 보는게 이득인 쓰레기 영화.,\n",
      " cg다시보고싶다,\n",
      " 소재가 아름다운 영화. 다소 아쉬운 부분들이 있는 이유는 이 영화는 영화스러운 극적 로맨스보단, 좀 더 사실적으로 한 남자의 마음과 시선을 말하고 싶었기 때문 아닐까.]\n"
     ]
    }
   ],
   "source": [
    "pprint(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.69      0.75      5014\n",
      "          1       0.73      0.86      0.79      4986\n",
      "\n",
      "avg / total       0.78      0.77      0.77     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TfidVectorizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "clf_2 = Pipeline([\n",
    "            ('vect', TfidfVectorizer()), \n",
    "            ('clf', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True...rue,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.69      0.75      5014\n",
      "          1       0.73      0.86      0.79      4986\n",
      "\n",
      "avg / total       0.78      0.77      0.77     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 형태소 분석기 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "pos_tagger = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "clf_3 = Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize_pos)), \n",
    "            ('clf', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        st...d8>,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[찮음/Noun,\n",
      " 자막/Noun,\n",
      " 고래/Noun,\n",
      " 괴벨스/Noun,\n",
      " 강간/Noun,\n",
      " 치료/Noun,\n",
      " 꽉/Noun,\n",
      " 계속계속/Adverb,\n",
      " 믿다/Verb,\n",
      " 슈나이더/Noun]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(clf_3.named_steps[\"vect\"].vocabulary_)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83      5014\n",
      "          1       0.83      0.82      0.83      4986\n",
      "\n",
      "avg / total       0.83      0.83      0.83     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
